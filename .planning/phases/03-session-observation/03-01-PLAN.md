---
phase: 03-session-observation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - scripts/observe-tool.sh
  - hooks/hooks.json
autonomous: true
requirements:
  - OBSV-01
  - OBSV-02
  - OBSV-03

must_haves:
  truths:
    - "PostToolUse hook fires after Write/Edit/Bash usage and appends a JSONL entry to session-log.jsonl"
    - "PostToolUseFailure hook fires after Bash errors and appends a JSONL error entry to session-log.jsonl"
    - "Each JSONL entry contains ts, event, tool, file or command, and session_id fields"
    - "The observation script executes in under 100ms"
  artifacts:
    - path: "scripts/observe-tool.sh"
      provides: "PostToolUse and PostToolUseFailure observation handler"
      contains: "case.*TOOL_NAME"
    - path: "hooks/hooks.json"
      provides: "Hook configuration for PostToolUse, PostToolUseFailure, and existing SessionStart"
      contains: "PostToolUse"
  key_links:
    - from: "hooks/hooks.json"
      to: "scripts/observe-tool.sh"
      via: "PostToolUse command hook reference"
      pattern: "observe-tool\\.sh"
    - from: "scripts/observe-tool.sh"
      to: ".auto-context/session-log.jsonl"
      via: "echo >> append"
      pattern: ">> .*session-log\\.jsonl"
---

<objective>
Create the PostToolUse observation hook that silently logs file modifications (Write/Edit) and command executions (Bash) to the session JSONL log, plus register PostToolUseFailure for Bash errors.

Purpose: This is the core data collection layer for auto-context. All downstream pattern extraction (Phase 5) and anti-pattern detection (Phase 7) depend on having structured session observation data.

Output: `scripts/observe-tool.sh` (executable), updated `hooks/hooks.json` with PostToolUse and PostToolUseFailure entries.
</objective>

<execution_context>
@/Users/dgsw67/.claude/get-shit-done/workflows/execute-plan.md
@/Users/dgsw67/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-session-observation/03-RESEARCH.md
@.planning/phases/01-plugin-skeleton-injection/01-01-SUMMARY.md
@hooks/hooks.json
@scripts/inject-context.sh
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create observe-tool.sh PostToolUse handler</name>
  <files>scripts/observe-tool.sh</files>
  <action>
Create `scripts/observe-tool.sh` as a bash script (#!/usr/bin/env bash, set -euo pipefail) that handles both PostToolUse and PostToolUseFailure events for the observation layer.

**Performance-critical design (OBSV-03):** Use a SINGLE jq invocation to extract all needed fields, avoiding multiple process spawns. The research documents that each `echo | jq` spawns a ~5-10ms process on macOS, so extracting 4 fields individually would consume 20-40ms of the 100ms budget.

**Implementation:**

1. Read stdin once: `INPUT=$(cat)`

2. Extract all common fields in ONE jq call using @tsv:
   ```bash
   IFS=$'\t' read -r TOOL_NAME SESSION_ID CWD HOOK_EVENT <<< "$(echo "$INPUT" | jq -r '[.tool_name, .session_id, .cwd, .hook_event_name] | @tsv')"
   ```

3. Set up paths:
   ```bash
   TS=$(date -u +%Y-%m-%dT%H:%M:%SZ)
   STORE_DIR="${CWD}/.auto-context"
   LOG_FILE="${STORE_DIR}/session-log.jsonl"
   ```

4. Safety net: ensure store dir and log file exist (in case SessionStart did not run):
   ```bash
   [ -d "$STORE_DIR" ] || mkdir -p "$STORE_DIR"
   [ -f "$LOG_FILE" ] || touch "$LOG_FILE"
   ```

5. Handle PostToolUseFailure FIRST (check HOOK_EVENT):
   If `HOOK_EVENT` equals "PostToolUseFailure", use a SINGLE jq -c call to construct the entire JSONL entry:
   ```bash
   echo "$INPUT" | jq -c --arg ts "$TS" '{ts:$ts, event:"bash_error", tool:"Bash", command:(.tool_input.command // "" | .[0:200]), error:(.error // "" | .[0:200]), session_id:.session_id}' >> "$LOG_FILE"
   ```
   Then `exit 0`.

6. Handle PostToolUse events by dispatching on TOOL_NAME:

   - **Write case:** Use jq -c to construct entry with event "file_write", tool "Write", file from `.tool_input.file_path`:
     ```bash
     echo "$INPUT" | jq -c --arg ts "$TS" '{ts:$ts, event:"file_write", tool:"Write", file:.tool_input.file_path, session_id:.session_id}' >> "$LOG_FILE"
     ```

   - **Edit case:** Same structure but event "file_edit", tool "Edit", file from `.tool_input.file_path`:
     ```bash
     echo "$INPUT" | jq -c --arg ts "$TS" '{ts:$ts, event:"file_edit", tool:"Edit", file:.tool_input.file_path, session_id:.session_id}' >> "$LOG_FILE"
     ```

   - **Bash case:** Include truncated command (max 200 chars):
     ```bash
     echo "$INPUT" | jq -c --arg ts "$TS" '{ts:$ts, event:"bash_command", tool:"Bash", command:(.tool_input.command // "" | .[0:200]), session_id:.session_id}' >> "$LOG_FILE"
     ```

   - **Default (*):** Do nothing, exit 0. Silently ignore unknown tools.

7. Always `exit 0` at the end.

**CRITICAL anti-patterns to avoid (from research):**
- Do NOT log `tool_input.content` (Write) or `tool_response` -- metadata only, no raw content
- Do NOT log full `tool_response` for Bash -- can be enormous (test suites, build output)
- Do NOT read or parse session-log.jsonl during observation -- append only
- Use `jq -c` for JSON construction (not string interpolation) to handle escaping of command strings with quotes/newlines
- Truncate command and error fields to 200 chars to prevent log bloat

After creating the file, run: `chmod +x scripts/observe-tool.sh`
  </action>
  <verify>
    <automated>cd /Users/dgsw67/auto-context && bash -n scripts/observe-tool.sh && test -x scripts/observe-tool.sh && echo "PASS: syntax valid, executable" || echo "FAIL"</automated>
    <manual>Verify the script handles Write, Edit, Bash, and PostToolUseFailure cases with single-jq field extraction</manual>
  </verify>
  <done>scripts/observe-tool.sh exists, is executable, passes bash -n syntax check, handles Write/Edit/Bash/PostToolUseFailure cases, uses single-jq extraction for performance, logs only metadata (no content/response), truncates commands to 200 chars</done>
</task>

<task type="auto">
  <name>Task 2: Register PostToolUse and PostToolUseFailure hooks in hooks.json</name>
  <files>hooks/hooks.json</files>
  <action>
Update `hooks/hooks.json` to add PostToolUse and PostToolUseFailure entries alongside the existing SessionStart hook.

Read the current hooks.json first. It currently has only a SessionStart entry. Add:

1. **PostToolUse** entry with matcher `Write|Edit|Bash` pointing to `${CLAUDE_PLUGIN_ROOT}/scripts/observe-tool.sh`
2. **PostToolUseFailure** entry with matcher `Bash` pointing to the same `${CLAUDE_PLUGIN_ROOT}/scripts/observe-tool.sh`

The final hooks.json structure should be:
```json
{
  "hooks": {
    "SessionStart": [
      {
        "hooks": [
          {
            "type": "command",
            "command": "${CLAUDE_PLUGIN_ROOT}/scripts/inject-context.sh"
          }
        ]
      }
    ],
    "PostToolUse": [
      {
        "matcher": "Write|Edit|Bash",
        "hooks": [
          {
            "type": "command",
            "command": "${CLAUDE_PLUGIN_ROOT}/scripts/observe-tool.sh"
          }
        ]
      }
    ],
    "PostToolUseFailure": [
      {
        "matcher": "Bash",
        "hooks": [
          {
            "type": "command",
            "command": "${CLAUDE_PLUGIN_ROOT}/scripts/observe-tool.sh"
          }
        ]
      }
    ]
  }
}
```

Preserve exact formatting (2-space indentation, consistent with existing file). Do NOT add SessionEnd yet -- that belongs to Plan 02.

After updating, validate the JSON is well-formed with: `jq . hooks/hooks.json > /dev/null`

**Integration test:** Simulate a PostToolUse Write event to verify the full pipeline works:
```bash
mkdir -p /tmp/ac-test-03/.auto-context
echo '{"session_id":"test123","cwd":"/tmp/ac-test-03","hook_event_name":"PostToolUse","tool_name":"Write","tool_input":{"file_path":"/tmp/ac-test-03/src/app.ts","content":"test"},"tool_response":{"success":true}}' | bash scripts/observe-tool.sh
cat /tmp/ac-test-03/.auto-context/session-log.jsonl
```
Verify the output line contains: ts, event "file_write", tool "Write", file path, session_id.

Then test Bash:
```bash
echo '{"session_id":"test123","cwd":"/tmp/ac-test-03","hook_event_name":"PostToolUse","tool_name":"Bash","tool_input":{"command":"npm test","description":"Run tests"},"tool_response":{"stdout":"ok","exitCode":0}}' | bash scripts/observe-tool.sh
```

Then test PostToolUseFailure:
```bash
echo '{"session_id":"test123","cwd":"/tmp/ac-test-03","hook_event_name":"PostToolUseFailure","tool_name":"Bash","tool_input":{"command":"npm test"},"error":"Command exited with non-zero status","is_interrupt":false}' | bash scripts/observe-tool.sh
```

Then verify all 3 entries in the log:
```bash
wc -l /tmp/ac-test-03/.auto-context/session-log.jsonl  # Should be 3
jq . /tmp/ac-test-03/.auto-context/session-log.jsonl    # Should parse each line as valid JSON
```

Clean up: `rm -rf /tmp/ac-test-03`
  </action>
  <verify>
    <automated>cd /Users/dgsw67/auto-context && jq . hooks/hooks.json > /dev/null && mkdir -p /tmp/ac-test-03/.auto-context && echo '{"session_id":"t1","cwd":"/tmp/ac-test-03","hook_event_name":"PostToolUse","tool_name":"Write","tool_input":{"file_path":"/tmp/f.ts","content":"x"},"tool_response":{"success":true}}' | bash scripts/observe-tool.sh && echo '{"session_id":"t1","cwd":"/tmp/ac-test-03","hook_event_name":"PostToolUse","tool_name":"Bash","tool_input":{"command":"npm test"},"tool_response":{"exitCode":0}}' | bash scripts/observe-tool.sh && echo '{"session_id":"t1","cwd":"/tmp/ac-test-03","hook_event_name":"PostToolUseFailure","tool_name":"Bash","tool_input":{"command":"npm test"},"error":"exit 1","is_interrupt":false}' | bash scripts/observe-tool.sh && test "$(wc -l < /tmp/ac-test-03/.auto-context/session-log.jsonl | tr -d ' ')" = "3" && jq -e . /tmp/ac-test-03/.auto-context/session-log.jsonl > /dev/null && rm -rf /tmp/ac-test-03 && echo "PASS: hooks.json valid, 3 events logged as valid JSONL" || (rm -rf /tmp/ac-test-03; echo "FAIL")</automated>
  </verify>
  <done>hooks.json contains PostToolUse (matcher Write|Edit|Bash) and PostToolUseFailure (matcher Bash) entries pointing to observe-tool.sh. Integration test confirms Write, Bash, and Bash error events each produce valid JSONL entries in session-log.jsonl. Three events = three lines.</done>
</task>

</tasks>

<verification>
1. `bash -n scripts/observe-tool.sh` passes (no syntax errors)
2. `scripts/observe-tool.sh` is executable (`test -x`)
3. `jq . hooks/hooks.json` parses without error
4. hooks.json has PostToolUse with matcher "Write|Edit|Bash"
5. hooks.json has PostToolUseFailure with matcher "Bash"
6. Simulated Write event produces valid JSONL with event "file_write"
7. Simulated Bash event produces valid JSONL with event "bash_command" and truncated command
8. Simulated PostToolUseFailure event produces valid JSONL with event "bash_error" and error field
9. All JSONL entries contain ts, event, tool, session_id fields
</verification>

<success_criteria>
- observe-tool.sh handles Write, Edit, Bash (PostToolUse) and Bash (PostToolUseFailure) events
- Each event produces exactly one JSONL line appended to session-log.jsonl
- No file content or tool response is logged (metadata only)
- Command strings truncated to 200 characters
- Single jq invocation for field extraction (performance)
- hooks.json is valid JSON with all three hook event types
</success_criteria>

<output>
After completion, create `.planning/phases/03-session-observation/03-01-SUMMARY.md`
</output>
