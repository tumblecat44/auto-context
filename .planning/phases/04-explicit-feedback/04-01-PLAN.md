---
phase: 04-explicit-feedback
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - scripts/detect-feedback.sh
  - hooks/hooks.json
autonomous: true
requirements:
  - FDBK-01
  - FDBK-02
  - FDBK-03

must_haves:
  truths:
    - "User says 'remember this: use pnpm' and conventions.json gains an entry with source explicit and confidence 1.0"
    - "User says 'don't use var' and anti-patterns.json gains an entry with source explicit and confidence 1.0"
    - "User says '기억해: pnpm 써' and conventions.json gains a Korean-text entry"
    - "User says '하지 마: var 쓰지 마' and anti-patterns.json gains a Korean-text entry"
    - "Normal prompts like 'fix the bug' produce no side effects (fast exit)"
    - "Hook returns additionalContext confirming the captured feedback to Claude"
  artifacts:
    - path: "scripts/detect-feedback.sh"
      provides: "UserPromptSubmit feedback detection and data store writing"
      min_lines: 60
    - path: "hooks/hooks.json"
      provides: "UserPromptSubmit hook registration"
      contains: "UserPromptSubmit"
  key_links:
    - from: "hooks/hooks.json"
      to: "scripts/detect-feedback.sh"
      via: "UserPromptSubmit command hook registration"
      pattern: "detect-feedback\\.sh"
    - from: "scripts/detect-feedback.sh"
      to: ".auto-context/conventions.json"
      via: "jq atomic append for positive feedback"
      pattern: "conventions\\.json"
    - from: "scripts/detect-feedback.sh"
      to: ".auto-context/anti-patterns.json"
      via: "jq atomic append for negative feedback"
      pattern: "anti-patterns\\.json"
---

<objective>
Create the UserPromptSubmit hook that detects explicit user feedback ("remember this", "don't do this", Korean equivalents) and immediately persists it to conventions.json or anti-patterns.json with confidence 1.0 and source "explicit".

Purpose: Users can teach the plugin directly by saying "remember this" or "don't do this" -- the highest-confidence signal in the system, weighted 10x over implicit signals.
Output: scripts/detect-feedback.sh (new), hooks/hooks.json (updated with UserPromptSubmit entry)
</objective>

<execution_context>
@/Users/dgsw67/.claude/get-shit-done/workflows/execute-plan.md
@/Users/dgsw67/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-explicit-feedback/04-RESEARCH.md

# Existing codebase files this plan modifies or follows patterns from:
@hooks/hooks.json
@scripts/observe-tool.sh
@scripts/inject-context.sh
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create detect-feedback.sh UserPromptSubmit hook</name>
  <files>scripts/detect-feedback.sh</files>
  <action>
Create `scripts/detect-feedback.sh` as a UserPromptSubmit command hook. Follow the exact pattern from 04-RESEARCH.md Pattern 1 with these specifics:

1. **Shebang and setup**: `#!/usr/bin/env bash` with `set -euo pipefail`. Read stdin once into INPUT variable (same pattern as observe-tool.sh).

2. **Field extraction**: Single jq call to extract `prompt`, `session_id`, `cwd` using `@tsv` (same pattern as observe-tool.sh line 11).

3. **Quick exit**: If prompt length < 5 chars, exit 0 immediately. This is the fast path for the majority of prompts.

4. **Safety net**: Ensure `.auto-context/` dir exists and conventions.json/anti-patterns.json are initialized (same pattern as observe-tool.sh lines 18-19, extended for JSON files with `echo '[]'`).

5. **Pattern matching** -- check NEGATIVE patterns FIRST (more specific, avoids false positive overlap):
   - English (case-insensitive via tr lowercase): `grep -qE "(don'?t (do|use|ever)|never (do|use)|stop (doing|using)|avoid )"`
   - Korean (fixed string, UTF-8): `grep -qF "하지 마"`, `grep -qF "하지마"`, `grep -qF "쓰지 마"`, `grep -qF "쓰지마"`

   Then check POSITIVE patterns:
   - English: `grep -qE "(remember( this| that|:)|always (do|use)|from now on)"`
   - Korean: `grep -qF "기억해"`, `grep -qF "앞으로"`

6. **Instruction extraction**: Use sed to strip the trigger phrase prefix, keeping the instruction content. Trim whitespace, limit to 500 chars via `head -c 500`. Fallback to full prompt if extraction produces empty string.

7. **Data store write**: Use `jq --arg` to append entry with fields: `text`, `confidence` (1.0), `source` ("explicit"), `created_at` (ISO 8601 UTC), `session_id`. Write to .tmp file then `mv` for atomic rename (prevents corruption from concurrent writes).

8. **Session log entry**: Also append a JSONL line to session-log.jsonl: `{"ts":"...","event":"explicit_feedback","type":"convention|anti-pattern","text":"...","session_id":"..."}` -- this gives Phase 5 visibility into explicit feedback events.

9. **Output**: Return JSON with `hookSpecificOutput.additionalContext` confirming the capture (e.g., "Auto-Context captured explicit convention: always use pnpm"). Use `hookEventName: "UserPromptSubmit"`.

10. **Make executable**: `chmod +x scripts/detect-feedback.sh`.

IMPORTANT: The confidence 1.0 value implements FDBK-03 (10x weight). Bootstrap conventions use 0.6-0.9 with source "bootstrap". The downstream lifecycle (Phase 6/7) will use source + confidence to compute effective weight: explicit at 1.0 is 10x the 0.1 baseline for implicit signals.

AVOID: Do NOT use Python or Node for pattern matching (adds dependency, 200ms+ startup). Do NOT write to CLAUDE.md directly (injection happens at SessionStart). Do NOT use exit code 2 (would block/erase the user's prompt). Do NOT use broad patterns like bare "remember" (causes false positives with "I remember seeing this bug").
  </action>
  <verify>
    <automated>bash -n /Users/dgsw67/auto-context/scripts/detect-feedback.sh && test -x /Users/dgsw67/auto-context/scripts/detect-feedback.sh && echo "PASS: syntax valid and executable"</automated>
    <manual>
Functional tests via echo piping:

# Test positive English detection
echo '{"prompt":"remember this: always use pnpm","session_id":"test1","cwd":"/tmp/ac-test"}' | bash scripts/detect-feedback.sh
# Expect: additionalContext with "convention" and conventions.json entry

# Test negative English detection
echo '{"prompt":"dont use var, use const instead","session_id":"test1","cwd":"/tmp/ac-test"}' | bash scripts/detect-feedback.sh
# Expect: additionalContext with "anti-pattern" and anti-patterns.json entry

# Test Korean positive
echo '{"prompt":"기억해: pnpm을 사용해","session_id":"test1","cwd":"/tmp/ac-test"}' | bash scripts/detect-feedback.sh
# Expect: convention entry in conventions.json

# Test Korean negative
echo '{"prompt":"var 하지 마","session_id":"test1","cwd":"/tmp/ac-test"}' | bash scripts/detect-feedback.sh
# Expect: anti-pattern entry in anti-patterns.json

# Test no-op (normal prompt)
echo '{"prompt":"fix the login bug","session_id":"test1","cwd":"/tmp/ac-test"}' | bash scripts/detect-feedback.sh
# Expect: no output, exit 0, no file changes
    </manual>
  </verify>
  <done>detect-feedback.sh is executable, passes bash -n syntax check. Positive English/Korean triggers write to conventions.json with confidence 1.0 and source "explicit". Negative English/Korean triggers write to anti-patterns.json with same schema. Normal prompts exit silently in under 10ms. All JSON writes use atomic tmp+mv pattern. Session log gets explicit_feedback JSONL entry.</done>
</task>

<task type="auto">
  <name>Task 2: Register UserPromptSubmit hook in hooks.json</name>
  <files>hooks/hooks.json</files>
  <action>
Update `hooks/hooks.json` to add a UserPromptSubmit entry. The hook registration follows the exact same pattern as existing entries.

Add this entry AFTER SessionStart and BEFORE PostToolUse (logical ordering: session lifecycle -> user prompt -> tool usage):

```json
"UserPromptSubmit": [
  {
    "hooks": [
      {
        "type": "command",
        "command": "${CLAUDE_PLUGIN_ROOT}/scripts/detect-feedback.sh"
      }
    ]
  }
]
```

NOTE: UserPromptSubmit does NOT support matchers (it fires on every prompt). This is correct -- the hook itself handles the fast-exit path for non-feedback prompts.

Preserve all existing hook entries exactly as they are (SessionStart, PostToolUse, PostToolUseFailure, SessionEnd).

After modification, validate the JSON is valid with `jq .`.
  </action>
  <verify>
    <automated>jq . /Users/dgsw67/auto-context/hooks/hooks.json > /dev/null && jq -e '.hooks.UserPromptSubmit' /Users/dgsw67/auto-context/hooks/hooks.json > /dev/null && echo "PASS: hooks.json valid with UserPromptSubmit"</automated>
  </verify>
  <done>hooks.json contains UserPromptSubmit entry pointing to detect-feedback.sh. All existing hook entries (SessionStart, PostToolUse, PostToolUseFailure, SessionEnd) are preserved. JSON validates with jq.</done>
</task>

</tasks>

<verification>
1. `bash -n scripts/detect-feedback.sh` -- syntax valid
2. `test -x scripts/detect-feedback.sh` -- executable
3. `jq . hooks/hooks.json` -- valid JSON
4. `jq -e '.hooks.UserPromptSubmit[0].hooks[0].command' hooks/hooks.json` -- hook registered
5. Functional: positive English -> conventions.json entry with confidence 1.0
6. Functional: negative English -> anti-patterns.json entry with confidence 1.0
7. Functional: Korean triggers work for both positive and negative
8. Functional: normal prompt -> no output, no file changes, fast exit
9. Functional: session-log.jsonl gets explicit_feedback JSONL entry
</verification>

<success_criteria>
- detect-feedback.sh handles English and Korean positive/negative trigger phrases
- Conventions written with `confidence: 1.0` and `source: "explicit"` (10x weight baseline per FDBK-03)
- Anti-patterns written with same schema to anti-patterns.json
- hooks.json registers UserPromptSubmit pointing to detect-feedback.sh
- Normal prompts produce zero side effects (fast exit path)
- Atomic JSON writes prevent corruption from concurrent hook invocations
</success_criteria>

<output>
After completion, create `.planning/phases/04-explicit-feedback/04-01-SUMMARY.md`
</output>
